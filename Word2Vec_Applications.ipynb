{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec Model\n",
    "\n",
    " - Word2Vec Google's Pretrained Model.\n",
    " - Contains Vector Representations Of 50 Billion Words.\n",
    " - Words Which Are Similar In Context Have Similar Vectors.\n",
    " - Distance/Similarity Between Two Words Can Be Measured Using Cosine Distance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applications\n",
    " \n",
    " - Text Similarity\n",
    " - Language Translation\n",
    " - Finding Odd Words\n",
    " - Word Analogies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Embeddings\n",
    "\n",
    " - Word Embeddings Are Numerical Representation Of Words, In The Form Of Vectors.\n",
    " - Word2Vec Model Represents Each Word As 300 Dimensional Vector.\n",
    " - Using The Pre-trained Model For Different Applications.\n",
    " - Model Size Is Around 3.64 GB. (Around 50 Billion Words)\n",
    " - Will Work Using Gensim, A Popular NLP Package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gensim's Word2Vec Model Provides Optimum Implementation Of**\n",
    " \n",
    " 1. **CBOW** Model (Continuous Bag Of Words Model)\n",
    " 2. **SkipGram** Model\n",
    " \n",
    "- Paper 1 : Efficient Estimation Of Word Representation In Vector Space\n",
    "- Paper 2 : Distributed Representations Of Words And Phrases And Their Compositionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word2Vec Using Gensim\n",
    "\n",
    "**Link** : https://radimrehurek.com/gensim/models/word2vec.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Word2Vec Model\n",
    "\n",
    "**Keyed Vectors** - *This Object Essentially Contains The Mapping Between Words And Embeddings. After Training, It Can Be Used Directly To Query Those Embeddings In Various Ways*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gensim\n",
    "from gensim.models import word2vec\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models import Word2Vec\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.manifold import TSNE\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore',category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin',binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300,) (300,)\n"
     ]
    }
   ],
   "source": [
    "vec_peach = word_vectors[\"peach\"]\n",
    "vec_mango = word_vectors[\"mango\"]\n",
    "\n",
    "print(vec_peach.shape, vec_mango.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.56328726]]\n"
     ]
    }
   ],
   "source": [
    "print(cosine_similarity([vec_peach],[vec_mango]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application 1 : Find The Odd One Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def odd_one_out(words):\n",
    "    \"\"\" Accepts A List Of Words And Returns The Odd Word\"\"\"\n",
    "    \n",
    "    # 1. Average Vector Of All The Vectors In The List.\n",
    "    # 2. Cosine_Similarity(Word, Avg) For All Words.\n",
    "    # 3. Minimum(Cosine_Similarity)\n",
    "    \n",
    "    # Generate All Word Embeddings For The Given List\n",
    "    all_word_vectors = [word_vectors[w] for w in words]\n",
    "    avg_vector = np.mean(all_word_vectors, axis=0) # Axis = 0, Means Mean Across All The Rows\n",
    "\n",
    "    # Iterate Over Every Word And Find The Similarity\n",
    "    odd_one_out = None\n",
    "    min_similarity = 1.0\n",
    "    for w in words:\n",
    "        sim = cosine_similarity([word_vectors[w]], [avg_vector])\n",
    "        if sim < min_similarity:\n",
    "            min_similarity = sim\n",
    "            odd_one_out = w\n",
    "        print(\"Similarity Between %s And Average Vector Is %.2f !\"%(w,sim))\n",
    "    \n",
    "    return odd_one_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_1 = [\"apple\", \"mango\", \"juice\", \"party\", \"orange\"]\n",
    "input_2 = [\"music\", \"dance\", \"sleep\", \"dancer\", \"food\"]\n",
    "input_3 = [\"match\", \"player\", \"football\", \"cricket\", \"dancer\"]\n",
    "input_4 = [\"india\", \"paris\", \"russia\", \"france\", \"germany\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity Between apple And Average Vector Is 0.78 !\n",
      "Similarity Between mango And Average Vector Is 0.76 !\n",
      "Similarity Between juice And Average Vector Is 0.71 !\n",
      "Similarity Between party And Average Vector Is 0.36 !\n",
      "Similarity Between orange And Average Vector Is 0.65 !\n",
      "\n",
      "Odd One Out :  party\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nOdd One Out : \", odd_one_out(input_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity Between music And Average Vector Is 0.66 !\n",
      "Similarity Between dance And Average Vector Is 0.81 !\n",
      "Similarity Between sleep And Average Vector Is 0.51 !\n",
      "Similarity Between dancer And Average Vector Is 0.72 !\n",
      "Similarity Between food And Average Vector Is 0.52 !\n",
      "\n",
      "Odd One Out :  sleep\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nOdd One Out : \", odd_one_out(input_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity Between match And Average Vector Is 0.58 !\n",
      "Similarity Between player And Average Vector Is 0.68 !\n",
      "Similarity Between football And Average Vector Is 0.72 !\n",
      "Similarity Between cricket And Average Vector Is 0.70 !\n",
      "Similarity Between dancer And Average Vector Is 0.53 !\n",
      "\n",
      "Odd One Out :  dancer\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nOdd One Out : \", odd_one_out(input_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity Between india And Average Vector Is 0.81 !\n",
      "Similarity Between paris And Average Vector Is 0.75 !\n",
      "Similarity Between russia And Average Vector Is 0.79 !\n",
      "Similarity Between france And Average Vector Is 0.81 !\n",
      "Similarity Between germany And Average Vector Is 0.84 !\n",
      "\n",
      "Odd One Out :  paris\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nOdd One Out : \", odd_one_out(input_4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application 2 : Word Analogies Task\n",
    "\n",
    " - In The Word Analogy Task, We Complete The Sentence \"a is to b as c is to __\".\n",
    " - An Example Is, \"man is to woman as king is to queen\".\n",
    " - In Detail, We Are Trying To Find A Word 'd', Such That The Associated Word Vectors ea, eb, ec, ed Are Related In The Following Manner : (eb - ea) â‰ˆ (ed - ec).\n",
    " - We Will Measure The Similarity Between (eb - ea) And (ed - ec) Using Cosine Similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_word(a, b, c, word_vectors):\n",
    "    \"\"\" Accepts A Triad Of Words, a, b, c And Returns d Such That 'a is to b : c is to d'.\"\"\"\n",
    "    \n",
    "    a, b, c = a.lower(), b.lower(), c.lower()\n",
    "    \n",
    "    # Similarity |b-a| = |d-c| Should Be Max\n",
    "    max_similarity = -100\n",
    "    d = None\n",
    "    \n",
    "    words = word_vectors.vocab.keys()\n",
    "    wa, wb, wc = word_vectors[a], word_vectors[b], word_vectors[c]\n",
    "    \n",
    "    # To Find 'd' Such That Similarity (|b-a|, |d-c|) Should Be Max.\n",
    "    for w in words:\n",
    "        if w in [a,b,c]:\n",
    "            continue\n",
    "        \n",
    "        wv = word_vectors[w]\n",
    "        sim = cosine_similarity([wb-wa], [wv-wc])\n",
    "        \n",
    "        if sim > max_similarity:\n",
    "            max_similarity = sim\n",
    "            d = w\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "princess\n"
     ]
    }
   ],
   "source": [
    "triad_1 = (\"man\", \"woman\", \"prince\")\n",
    "print(predict_word(*triad_1, word_vectors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using The Most Similar Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('queen', 0.7118192911148071)]\n"
     ]
    }
   ],
   "source": [
    "print(word_vectors.most_similar(positive=['woman', 'king'], negative=['man'], topn=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('queen', 0.7118192911148071), ('monarch', 0.6189674139022827), ('princess', 0.5902431011199951), ('crown_prince', 0.5499460697174072), ('prince', 0.5377321243286133)]\n"
     ]
    }
   ],
   "source": [
    "print(word_vectors.most_similar(positive=['woman', 'king'], negative=['man'], topn=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('teenager', 0.5787034034729004), ('woman', 0.5065137147903442), ('youngster', 0.49353092908859253), ('guy', 0.49308693408966064), ('teen_ager', 0.48808714747428894)]\n"
     ]
    }
   ],
   "source": [
    "print(word_vectors.most_similar(positive=['boy','man'], negative=['girl'], topn=5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
